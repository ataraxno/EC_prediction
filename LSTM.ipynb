{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package is ready.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 16)\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "print(\"Package is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load them!\n",
    "l = np.load(\"./Data/ECtrainset_wRWEC.npz\")\n",
    "\n",
    "# See what's in here\n",
    "print (l.files)\n",
    "\n",
    "# get data\n",
    "train_data = l['traindataset']\n",
    "train_label = l['trainlabel']\n",
    "test_data = l['testdataset']\n",
    "test_label = l['testlabel']\n",
    "\n",
    "mins = l['mins']\n",
    "maxs = l['maxs']\n",
    "\n",
    "labelmins = l['labelmins']\n",
    "labelmaxs = l['labelmaxs']\n",
    "\n",
    "explanation = \"RWEC_LSTM_24\"\n",
    "DELETE = [3, 4, 5, 11, 12]\n",
    "EX_PRED = 0 #Sorry, it's not automated yet.\n",
    "\n",
    "train_data = np.delete(train_data, DELETE, axis=1)\n",
    "test_data = np.delete(test_data, DELETE, axis=1)\n",
    "train_label = train_label[:,:]\n",
    "test_label = test_label[:,:]\n",
    "\n",
    "print(train_data[:5])\n",
    "print(train_label[:5])\n",
    "print(test_data[:5])\n",
    "print(test_label[:5])\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data setting\n",
    "n_train = train_label.shape[0]\n",
    "n_test = test_label.shape[0]\n",
    "n_input = train_data.shape[1]\n",
    "n_output = test_label.shape[1]\n",
    "n_classes = n_output\n",
    "\n",
    "print(\"# train: %d # test: %d, # input: %d, # output: %d\" % (n_train, n_test, n_input, n_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10000\n",
    "batch_size = n_train\n",
    "display_step = 500\n",
    "\n",
    "# Network Parameters\n",
    "n_steps = 10 # 1.5 day\n",
    "n_hidden = 64 # hidden layer num of features\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_output])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_output]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_output]))\n",
    "}\n",
    "\n",
    "print(\"parameters are ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load them!\n",
    "l = np.load(\"./Data/ECpredset_wRWEC.npz\")\n",
    "\n",
    "# See what's in here\n",
    "print (l.files)\n",
    "\n",
    "# get data\n",
    "pred_data = l['preddataset']\n",
    "pred_label = l['predlabel']\n",
    "n_pred = pred_label.shape[0]\n",
    "\n",
    "print(pred_data[0])\n",
    "print(pred_label[0])\n",
    "\n",
    "print(pred_data.shape)\n",
    "print(pred_label.shape)\n",
    "\n",
    "#Processing\n",
    "\n",
    "for i in range(pred_data.shape[1]):\n",
    "    temp = pred_data[:,i]\n",
    "    temp = (temp - mins[i]) / (maxs[i] - mins[i])\n",
    "    pred_data[:,i] = temp\n",
    "\n",
    "    \n",
    "for i in range(pred_label.shape[1]):\n",
    "    temp = pred_label[:,i]\n",
    "    temp = (temp - labelmins[i]) / (labelmaxs[i] - labelmins[i])\n",
    "    pred_label[:,i] = temp\n",
    "    \n",
    "pred_data = np.delete(pred_data, DELETE, axis=1)\n",
    "\n",
    "pred_x = pred_data.reshape((-1, n_steps, n_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "    \n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, n_steps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "print(\"parameters are ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.multiply(tf.reduce_sum(tf.square(tf.subtract(pred, y))),1/batch_size)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "ymean = tf.reduce_mean(y)\n",
    "SSE = tf.reduce_sum(tf.square(tf.subtract(y, pred)))\n",
    "SSR = tf.reduce_sum(tf.square(tf.subtract(pred, ymean)))\n",
    "r_squared = SSR/(SSE+SSR)\n",
    "                                \n",
    "accuracy = r_squared\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Do some optimizations\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))\n",
    "sess.run(init)\n",
    "\n",
    "print(\"seesion start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary writer\n",
    "tf.summary.scalar('RMS', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "directory_name = \"./tb_logs/\" + explanation + str(n_hidden)\n",
    "summary_writer = tf.summary.FileWriter(directory_name, graph=sess.graph)\n",
    "print (\"Summary ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = train_data.shape[0]\n",
    "int(num_data/batch_size/n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = train_data\n",
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y = train_label[i:i+batch_size, :]\n",
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "num_data = train_data.shape[0]\n",
    "ex_pred_acc = EX_PRED\n",
    "\n",
    "# Keep training until reach max iterations\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(num_data/batch_size/n_steps)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_x = train_data[i:i+n_steps*batch_size, :]\n",
    "        batch_y = train_label[i:i+batch_size, :]\n",
    "        \n",
    "        # Reshape data\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "        # Run optimization op (backprop)\n",
    "        summary, _ = sess.run([merged, optimizer], feed_dict={x: batch_x, y: batch_y})\n",
    "        avg_cost += sess.run(cost, feed_dict={x: batch_x, y: batch_y})/total_batch\n",
    "        summary_writer.add_summary(summary, epoch*total_batch+i)\n",
    "        \n",
    "        pred_acc = sess.run(accuracy, feed_dict={x: pred_x, y: pred_label})\n",
    "\n",
    "    if pred_acc > ex_pred_acc:\n",
    "        bestpath = \"./models/best_trained_\" + explanation + \".ckpt\"\n",
    "        save_path = saver.save(sess, bestpath)\n",
    "        ex_pred_acc = pred_acc\n",
    "        \n",
    "    if epoch % display_step == 0:\n",
    "        print (\"Epoch: %04d/%04d cost: %.6f, best: %.3f\" % (epoch, training_epochs, avg_cost,ex_pred_acc))\n",
    "        train_acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        test_x = test_data.reshape((-1, n_steps, n_input))\n",
    "        test_acc = sess.run(accuracy, feed_dict={x: test_x, y: test_label})\n",
    "        pred_acc = sess.run(accuracy, feed_dict={x: pred_x, y: pred_label})\n",
    "        print (\"Training Acc: %.3f, Validation Acc: %.3f, Test Acc: %.3f\" % (train_acc, test_acc, pred_acc))\n",
    "        \n",
    "            \n",
    "print (\"Epoch: %04d/%04d cost: %.6f\" % (epoch+1, training_epochs, avg_cost))\n",
    "train_acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "test_x = test_data.reshape((-1, n_steps, n_input))\n",
    "test_acc = sess.run(accuracy, feed_dict={x: test_x, y: test_label})\n",
    "print (\"Training Acc: %.3f, Validation Acc: %.3f, Test Acc: %.3f\" % (train_acc, test_acc, pred_acc))\n",
    "\n",
    "end = time.time() - start\n",
    "print (\"Optimization Finished\\ntraining time: %.2f sec.\" % (end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose best model\n",
    "bestpath = \"./models/best_trained_\" + explanation + \".ckpt\"\n",
    "saver.restore(sess, bestpath)\n",
    "# print(\"Model restored, best Acc: %.3f\" % ex_pred_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate accuracy for 128 mnist test images\n",
    "print (\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: pred_x, y: pred_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation = sess.run(pred, feed_dict={x: test_x, y: test_label})\n",
    "estimation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Data restoring\n",
    "for i in range(n_output):\n",
    "    estimation[:,i] = (labelmaxs[i] - labelmins[i]) * estimation[:,i] + labelmins[i]\n",
    "    test_label[:,i] = (labelmaxs[i] - labelmins[i]) * test_label[:,i] + labelmins[i]\n",
    "\n",
    "print(estimation[:5])\n",
    "print(test_label[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_RMSE = np.sum(np.sqrt((test_label - estimation)**2))/(estimation.shape[0]*18)\n",
    "\n",
    "print(\"valid RMSE: %.5f\" % valid_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_label.shape[1]):\n",
    "    print(i+1, r2_score(test_label[:, i], estimation[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#1:1 graph\n",
    "x_t = np.arange(-5, 10)\n",
    "y_t = x_t\n",
    "\n",
    "xny = plt.plot(x_t,y_t,'k')\n",
    "\n",
    "expect1 = plt.plot(test_label, estimation, 'b.')\n",
    "\n",
    "plt.axis([2, 6, 2, 6])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Measured EC', {'fontsize':20})\n",
    "plt.ylabel('Estimated EC',  {'fontsize':20})\n",
    "#plt.legend([expect1], [\"Mg\"], prop={'size': 12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_output = np.concatenate((test_label.T, estimation.T), axis=0).T\n",
    "\n",
    "file_name = \"regression_output_\" + explanation + \".CSV\"\n",
    "np.savetxt(\"./Results/\" + file_name, regression_output, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chronological graph\n",
    "x_t = np.arange(0, n_output)\n",
    "\n",
    "measured1 = plt.plot(x_t, test_label[55,:].T, 'k') #estimated\n",
    "\n",
    "expect1 = plt.plot(x_t, estimation[55,:].T, 'b') #estimated\n",
    "\n",
    "\n",
    "\n",
    "plt.axis([0, n_output-1, 3, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Time (h)', {'fontsize':20})\n",
    "plt.ylabel('EC',  {'fontsize':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chronological graph\n",
    "i = 72\n",
    "x_t = np.arange(0, n_output)\n",
    "\n",
    "measured1 = plt.plot(x_t, test_label[i,:].T, 'k') #estimated\n",
    "\n",
    "expect1 = plt.plot(x_t, estimation[i,:].T, 'b') #estimated\n",
    "\n",
    "\n",
    "\n",
    "plt.axis([0, n_output-1, 4, 5])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Time (h)', {'fontsize':20})\n",
    "plt.ylabel('EC',  {'fontsize':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chronological graph\n",
    "x_t = np.arange(0, n_output)\n",
    "\n",
    "measured1 = plt.plot(x_t, test_label[:20,:].T, 'k') #estimated\n",
    "expect1 = plt.plot(x_t, estimation[:20,:].T, 'b') #estimated\n",
    "\n",
    "plt.axis([0, n_output-1, 2, 6])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Time (h)', {'fontsize':20})\n",
    "plt.ylabel('EC',  {'fontsize':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load them!\n",
    "l = np.load(\"./Data/ECpredset_wRWEC.npz\")\n",
    "\n",
    "# See what's in here\n",
    "print (l.files)\n",
    "\n",
    "# get data\n",
    "pred_data = l['preddataset']\n",
    "pred_label = l['predlabel']\n",
    "n_pred = pred_label.shape[0]\n",
    "\n",
    "print(pred_data[0])\n",
    "print(pred_label[0])\n",
    "\n",
    "print(pred_data.shape)\n",
    "print(pred_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing\n",
    "\n",
    "for i in range(pred_data.shape[1]):\n",
    "    temp = pred_data[:,i]\n",
    "    temp = (temp - mins[i]) / (maxs[i] - mins[i])\n",
    "    pred_data[:,i] = temp\n",
    "\n",
    "    \n",
    "for i in range(pred_label.shape[1]):\n",
    "    temp = pred_label[:,i]\n",
    "    temp = (temp - labelmins[i]) / (labelmaxs[i] - labelmins[i])\n",
    "    pred_label[:,i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = np.delete(pred_data, DELETE, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_data[0])\n",
    "print(pred_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x = pred_data.reshape((-1, n_steps, n_input))\n",
    "\n",
    "print (\"Prediction Accuracy:\", sess.run(accuracy, feed_dict={x: pred_x, y: pred_label}))\n",
    "prediction = sess.run(pred, feed_dict={x: pred_x, y: pred_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data restoring\n",
    "for i in range(n_output):\n",
    "    prediction[:,i] = (labelmaxs[i] - labelmins[i]) * prediction[:,i] + labelmins[i]\n",
    "    pred_label[:,i] = (labelmaxs[i] - labelmins[i]) * pred_label[:,i] + labelmins[i]\n",
    "\n",
    "print(prediction[0])\n",
    "print(pred_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_RMSE = np.sum(np.sqrt((pred_label - prediction)**2))/(prediction.shape[0]*18)\n",
    "\n",
    "print(\"test RMSE: %.5f\" % test_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#1:1 graph\n",
    "x_t = np.arange(-5, 15)\n",
    "y_t = x_t\n",
    "\n",
    "xny = plt.plot(x_t,y_t,'k')\n",
    "\n",
    "expect1 = plt.plot(pred_label, prediction, 'b.')\n",
    "\n",
    "plt.axis([4, 5.5, 4, 5.5])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Measured EC', {'fontsize':20})\n",
    "plt.ylabel('Estimated EC',  {'fontsize':20})\n",
    "#plt.legend([expect1], [\"Mg\"], prop={'size': 12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RMSE_data = []\n",
    "for i in range(pred_label.shape[1]):\n",
    "    k = np.sum(np.sqrt((pred_label[:, i] - prediction[:, i])**2))/120\n",
    "    print(i+1, k)\n",
    "    RMSE_data.append(k)\n",
    "print(RMSE_data)\n",
    "\n",
    "\n",
    "x_t = np.arange(0, 18)\n",
    "y_t = x_t*0 + test_RMSE\n",
    "y2_t = x_t*0 + valid_RMSE\n",
    "\n",
    "RMSEs = plt.plot(x_t,RMSE_data, 'k')\n",
    "test_RMSE = plt.plot(x_t, y_t, 'k--')\n",
    "valid_RMSE = plt.plot(x_t, y2_t, 'k-')\n",
    "\n",
    "plt.axis([0, 17, 0, 0.2])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Time (h)', {'fontsize':20})\n",
    "plt.ylabel('EC',  {'fontsize':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chronological graph\n",
    "i = 0\n",
    "j = 11\n",
    "k = 72\n",
    "x_t = np.arange(0, 18)\n",
    "\n",
    "\n",
    "expect1 = plt.plot(x_t, prediction[i,:].T, 'b') #estimated\n",
    "measured1 = plt.plot(x_t, pred_label[i,:].T, 'b--') #estimated\n",
    "\n",
    "expect2 = plt.plot(x_t, prediction[j,:].T, 'r') #estimated\n",
    "measured2 = plt.plot(x_t, pred_label[j,:].T, 'r--') #estimated\n",
    "\n",
    "expect3 = plt.plot(x_t, prediction[k,:].T, 'g') #estimated\n",
    "measured3 = plt.plot(x_t, pred_label[k,:].T, 'g--') #estimated\n",
    "\n",
    "\n",
    "plt.axis([0, 17, 4.2, 5.2])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Time (h)', {'fontsize':20})\n",
    "plt.ylabel('EC',  {'fontsize':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chronological graph\n",
    "x_t = np.arange(0, 18)\n",
    "\n",
    "#measured1 = plt.plot(x_t, pred_label[:,:].T, 'k') #estimated\n",
    "expect1 = plt.plot(x_t, prediction[:15,:].T, 'b') #estimated\n",
    "\n",
    "plt.axis([0, 17, 4, 5.25])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Time (h)', {'fontsize':20})\n",
    "plt.ylabel('EC',  {'fontsize':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_output = np.concatenate((pred_label.T, prediction.T), axis=0).T\n",
    "\n",
    "file_name = \"pred_output_\" + explanation + \".CSV\"\n",
    "np.savetxt(\"./Results/\" + file_name, regression_output, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
